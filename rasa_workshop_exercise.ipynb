{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Building AI assistants that scale using machine learning and open source tools\n",
    "\n",
    "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaX3LNhGcAe1HnPZSuWS0oH6af0LJHXcH7If1sQgLCFAT1chNGFg)\n",
    "\n",
    "In this workshop, you will learn how to build your own conversational AI assistant using machine learning and real conversational data. The goal of this workshop is to walk you through the process of building an ML-powered assistant from scratch and build an actual assistant which you can improve later.\n",
    "\n",
    "\n",
    "There are no additional requirements to run this notebook, but if you encounter any issues or have more questions about the content included here, feel free send a message to an author of this exercise at juste@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "During the course of this 3-hour workshop, you will go through each stage of the chatbot development and build an assistant capable of recommending talks to attend in this conference and answer the questions about the event. Below is an example conversation your assistant will be able to handle:\n",
    "\n",
    "U: Hello  \n",
    "A: Hello! I am a conference assistant ready to help you find talks to attend or anwers any questions you have.  \n",
    "U: What session would you recommend for Data Scientists today?  \n",
    "A: You can attend 'Building AI assistnats that scale using machine learning and open source tools' session!  \n",
    "U: Who is the speaker and how long is the session?  \n",
    "A: The speaker is Justina. The session is 3 hours long.  \n",
    "U: Thanks!  \n",
    "A: You are very welcome!  \n",
    "\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "# Durante o curso deste workshop de 3 horas, você passará por cada etapa do desenvolvimento do chatbot e criará um assistente capaz de recomendar palestras para participar desta conferência e responder às perguntas sobre o evento. Abaixo está um exemplo de conversa que seu assistente poderá manipular:\n",
    "\n",
    "U: Olá\n",
    "Um olá! Eu sou um assistente de conferência pronto para ajudá-lo a encontrar palestras para participar ou anwers quaisquer perguntas que você tem.\n",
    "U: Qual sessão você recomendaria para os cientistas de dados hoje?\n",
    "R: Você pode participar da sessão 'Building AI assistnats que escala usando aprendizado de máquina e ferramentas open source'!\n",
    "U: Quem é o orador e quanto tempo dura a sessão?\n",
    "A: O orador é Justina. A sessão dura 3 horas.\n",
    "U: Obrigado!\n",
    "A: Você é muito bem vindo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The workshop consists of the following stages:\n",
    "\n",
    "**0. Intro:**  \n",
    "    0.1 Setup and installation \n",
    "      \n",
    "**1. Stage 1: Natural language understanding:**  \n",
    "    1.1. Designing the happy path  \n",
    "    1.2. Generating the NLU training examples  \n",
    "    1.3. Designing the training pipeline  \n",
    "    1.4. Training the first NLU model  \n",
    "    1.5.  Handling out-of-scope inputs  \n",
    "    1.6. Adding sinonyms  \n",
    "    1.7. Adding multi-intents  \n",
    "    1.8. Re-training and thesting the updated NLU model  \n",
    "      \n",
    "**2. Stage 2: Dialogue management model:**  \n",
    "    2.1. Designing training stories  \n",
    "    2.2. Setting up the backend component  \n",
    "    2.3. Creating a custom action  \n",
    "    2.4. Defining the domain  \n",
    "    2.5. Training the dialogue model  \n",
    "    2.6. Testing the dialogue model   \n",
    "    2.7. Handling out-of-scope conversations  \n",
    "    2.8. Adding stories with multi-intents  \n",
    "    2.9. Evaluating dialogue model  \n",
    "      \n",
    "**3. Stage 3: Closing the feedback loop:**  \n",
    "    3.1. Improving the assistant using the interactive learning   \n",
    "    3.2. Storing conversation history    \n",
    "    3.3. Connecting the assistant to the outside world  \n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "# O workshop consiste nas seguintes etapas:\n",
    "\n",
    "**0. Introdução:**\n",
    "    0.1 Configuração e instalação\n",
    "      \n",
    "**1. Estágio 1: compreensão da linguagem natural:**\n",
    "    1.1. Criando o caminho feliz\n",
    "    1.2. Gerando os Exemplos de Treinamento da NLU\n",
    "    1.3. Projetando o pipeline de treinamento\n",
    "    1.4. Treinando o primeiro modelo NLU\n",
    "    1.5. Manipulando Entradas Fora do Escopo\n",
    "    1.6. Adicionando sinônimos\n",
    "    1.7. Adicionando multi-intenções\n",
    "    1.8. Re-treinando e testando o modelo NLU atualizado\n",
    "      \n",
    "**2. Etapa 2: Modelo de gerenciamento de diálogo:**\n",
    "    2.1. Criando histórias de treinamento\n",
    "    2.2. Configurando o componente backend\n",
    "    2.3. Criando uma ação customizada\n",
    "    2.4. Definindo o domínio\n",
    "    2.5. Treinando o modelo de diálogo\n",
    "    2.6. Testando o modelo de diálogo\n",
    "    2.7. Lidando com conversas fora do escopo\n",
    "    2.8. Adicionando histórias com várias intenções\n",
    "    2.9. Avaliação do modelo de diálogo\n",
    "      \n",
    "**3. Estágio 3: fechando o ciclo de feedback:**\n",
    "    3.1. Melhorando o assistente usando o aprendizado interativo\n",
    "    3.2. Armazenando histórico de conversas\n",
    "    3.3. Conectando o assistente ao mundo exterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 0. Intro\n",
    "In this section, we will install all the necessary dependencies needed to successfully run this exercise.\n",
    "### 0.1. Setup and installation\n",
    "The best way to insall the necessary modules is to use the requirements.txt file. After creating a virtual environment, run:\n",
    "\n",
    "**pip install -r requirements.txt**\n",
    "\n",
    "Throughout this workshop, we will use only open source tools. The code block below checks if Rasa NLU and Rasa Core have been installed suffessfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 0. Introdução\n",
    "Nesta seção, instalaremos todas as dependências necessárias para executar este exercício com sucesso.\n",
    "### 0.1. Instalação e instalação\n",
    "A melhor maneira de instalar os módulos necessários é usar o arquivo requirements.txt. Depois de criar um ambiente virtual, execute:\n",
    "\n",
    "**pip install -r requirements.txt**\n",
    "\n",
    "Ao longo deste workshop, usaremos apenas ferramentas de código aberto. O bloco de código abaixo verifica se o Rasa NLU e o Rasa Core foram instalados sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa_nlu.__version__, rasa_core.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "### 0.2. Translate tutorial\n",
    "\n",
    "The good way to read a tutorial is in your native language, jupyter available for us a extension with Google translate.\n",
    "\n",
    "First verify the extension, just run in your terminal ```jupyter nbextension list```, and check the extension nbTranslate\n",
    "if you have not the extension installed in your computer, just **click on cell below** and **press ctrl + enter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.system(\"jupyter nbextension install https://rawgit.com/jfbercher/jupyter_nbTranslate/master/nbTranslate.zip --user\")\n",
    "os.system(\"jupyter nbextension enable nbTranslate/main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you already have the extension in your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.system(\"jupyter nbextension enable nbTranslate/main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this command, refresh your page to appear the settings translate on tool bar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1. Natural Language Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "In this section, you will enable your assistant to understand the user inputs by building a Rasa NLU model. This model will take unstructured user inputs and extract structured data in a form of intents and entities:  \n",
    "- *intent* - a label which represents the overall intention of the user 's input\n",
    "- *entity* - important detail which an assistant should extract and use to steer the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 1.1. Designing a happy path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good starting point is to define a happy path first. A happy path is a conversation flow where the user provides all the required information and allows the assistant to lead the conversation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 1.2. Designing the NLU training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "To train the NLU model you will need some labeled training data. Rasa NLU training data samples consist of the following components:  \n",
    "- intent label which starts with a prefix *\n",
    "- examples of text inputs which correspond to that label\n",
    "- entities which follow the format *[entity_value] (entity_label)*\n",
    "\n",
    "We will start by generating some training data examples by hand. For a completed data file check out the *helper_files/nlu_data.md* in the repository of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience)\n",
    "- for [product](relevant_audience) people\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "\n",
    "## 1.3 Designing the training pipeline\n",
    "\n",
    "Once the training data is ready, we can define the NLU model. We can do that by constructing the processing pipeline which defines how structured data will be extracted from unstructured user inputs: how the sentences will be tokenized, what intent classifier will be used, what entity extraction model will be used, etc. Each component in a training pipeline is trained one after another and can take inputs from the previously defined component as well as pass some information to subsequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"             # splits the sentence into tokens\n",
    "- name: \"ner_crf\"                   # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_count_vectors\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_tensorflow_embedding\"   # intent classifier\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1.4 Training the first Rasa NLU Model\n",
    "Now, we're going to train the NLU model to recognise user inputs, so that when you send a message like \"hello\" to your bot, it will recognise this as a \"greet\" intent. Let's define the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "def train_nlu_model():\n",
    "    # loading the nlu training samples\n",
    "    training_data = load_data(\"nlu.md\")\n",
    "\n",
    "    # trainer to educate our pipeline\n",
    "    trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "    # train the model!\n",
    "    interpreter = trainer.train(training_data)\n",
    "\n",
    "    # store it for future use\n",
    "    model_directory = trainer.persist(\"./models/current\", fixed_model_name=\"nlu\")\n",
    "    \n",
    "    return interpreter, model_directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Finally, let's train the model using the previously defined data and model configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Testing the model\n",
    "\n",
    "We have trained the first version of our NLU model! Let's test it on various inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper function to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))\n",
    "\n",
    "#change the input message with your prefered inputs\n",
    "input_message = \"What talks would you recommend to data scientists?\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Handling out-of-scope inputs\n",
    "When dealing with conversational AI, out-of-scope user inputs are very common challenge. These inputs represent the user requests which have nothing to do with the assistant's job. While it's very challenging to provide a sensible answer to each out-of-scope input, it's important to enable your assistant to identify such inputs and guide the user back to the conversation. First, let's enable our assistant to identify out-of-scope inputs. To do that, we will add a new intent called *out-of-scope* to our training dataset and provde some corresponding inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Let's retrain the model and see how it deals with out-of-scope inputs now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Vamos treinar novamente o modelo e ver como ele lida com as entradas fora do escopo agora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"I want pizza\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1.6 Adding synonyms\n",
    "\n",
    "Synonyms are a very useful Rasa NLU feature which maps extracted entities to the same name. It's used when some extracted values have to be normalised so that they could be used to query the database or make an API call. In our example, the occupation of the relevant audience is a good candidate for the synonym because users can provide the same occupation in a variety of different ways (for example, Machine Learning and ML). Let's update our training examples with synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience:ML) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience:ML) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience:ML)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "To train the NLU model with synonyms, we have to add the synonyms component to the model pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"             # splits the sentence into tokens\n",
    "- name: \"ner_crf\"                   # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_count_vectors\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_tensorflow_embedding\"   # intent classifier\n",
    "- name: \"ner_synonyms\"     #trains synonyms component\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Now, let's retrain the NLU model and test the performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "See how 'machine learning engineers' now gets mapped to 'ML':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"For machine learning engineers\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1.7 Implementing multi-intents\n",
    "\n",
    "The NLU model we have built so far works pretty well, but it only supports inputs with only one intent per user input. In this step, we will use a tensorflow embedding model to enable the assistant to recognise multi-intents - more than one intention per user input. Let's start by defining multi-intents in our training data. Multi-intents are defined in a very similar way as regular intents, the only difference is that the label names consists of intent tokens and a character of your choice that separates them, for example **intent_token1+intent_token2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience:ML) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience:ML) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience:ML)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\n",
    "\n",
    "## intent:speaker+length\n",
    " - Who is the presenter? Also, how long is the talk?\n",
    " - Who is the speaker and how long is the session?\n",
    " - Is the session long and who is presenting?\n",
    " - Do you know who is the presenter of the session? And how long is the session?\n",
    " - Is the talk long and who is presenting?\n",
    " - Who is the speaker? And how long is the talk?\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Next, let's modify the configuration of the model pipeline to use the tensorflow_embedding model with multi-intent support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"             # splits the sentence into tokens\n",
    "- name: \"ner_crf\"                   # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_count_vectors\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_tensorflow_embedding\"   # intent classifier\n",
    "  intent_tokenization_flag: true # sets multi-intent tokenization\n",
    "  intent_split_symbol: \"+\"       # sets which symbol should be used for tokenization\n",
    "- name: \"ner_synonyms\"   # trains synonyms component \n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Let's retrain the model with the new pipeline and test the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "See how a two-question input now gets recognised as a multi-intent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Who is the speakers and how long is the session?\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1.8 Evaluating the NLU model\n",
    "\n",
    "\n",
    "Testing the model on various inputs is a good way to get high-level insights into the performance of the model. However, it's a time consuming and quite a tedious way of testing. Instead of evaluating the model by hand, it can also be evaluated on a test data set (though for simplicity we are going to use the same for test and train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rasa_nlu.evaluate import run_evaluation\n",
    "import IPython\n",
    "from IPython import display\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Congratulations! You have just implemented the natural language understanding part of your assistant which means that your assistant can now understand you. In the second part of this workshop, we will delve into the next stage of the chatbot development - dialogue management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# 2. Dialogue Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "In this section of this workshop you will build a machine learning-based dialogue model which will enable your assistant to decide on how to respond to user inputs based on the state of the conversation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.1 Designing the training stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Let's start with generating the training data. Rasa Core models learn by observing real conversational data between the user and the assistant. The only important thing is that this data has to be converted into the Rasa Core format: user inputs have to be expressed as corresponding intents (and entities where necessary) while the responses of the assistant are expressed as action names. Each training story follows the format:  \n",
    "- the story starts with a story name which has a prefix ##  \n",
    "- intents, corresponding to user inputs, start with *  \n",
    "- if NLU model extracts entities which should influence the predictions of the dialogue model, they have to be included in the stories using the following format: * intent{'entity_name':\"entity_value\"}  \n",
    "- the responses of the bot start with -  \n",
    "- the story ends with an empty line which marks the end of the story\n",
    "\n",
    "In the next step of this tutorial, we will generate some training stories to cover the happy path. To see a complete training data example, check out the **data/stories.md** file of this repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "## happy path all info 1               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "## happy path all info 2               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks    \n",
    "  \n",
    "\n",
    "## happy path all info 3               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks  \n",
    "\n",
    "\n",
    "## happy path no relevant audience            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session\n",
    "  - utter_ask_relevant_audience\n",
    "* inform{\"relevant_audience\":\"Data Scientists\"}\n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.2 Setting up the backend component\n",
    "\n",
    "We want to make our assistant engaging and fun. For that reason, we will enable it to answer the questions using the real data stored in a SQL database. For this exercise, the assistant will be able to pull information about the conference agenda, talks, and speakers. Let's take a look at how the data in a SQL database looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as lite\n",
    "import pandas as pd\n",
    "\n",
    "conn = lite.connect('ConfDB.db')\n",
    "data = pd.read_sql_query(\"SELECT * FROM agenda LIMIT 10\", conn)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.3 Creating custom action\n",
    "\n",
    "We are going to use the backend integration to enable our assistant to fetch the relevant data based on user's queries. For that, we will create custom actions which, when predicted, will collect necessary data and use it to steer the conversation further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = \"\"\"\n",
    "from rasa_core_sdk import Action\n",
    "from rasa_core_sdk.events import SlotSet\n",
    "import sqlite3 as lite\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "class ActionRecommendTalk(Action):\n",
    "    def name(self):\n",
    "        return \"action_recommend_session\"\n",
    "        \n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        conn = lite.connect('ConfDB.db')\n",
    "        cur = conn.cursor()\n",
    "        relevant_audience = tracker.get_slot('relevant_audience')\n",
    "        cur.execute(\"SELECT * FROM agenda where relevant_audience like '%{}%'\".format(relevant_audience))\n",
    "\n",
    "        rows = cur.fetchall()\n",
    "        ind = random.randint(0,len(rows))\n",
    "        recommend_talk = list(rows[ind])\n",
    "        title = recommend_talk[0]\n",
    "        length = recommend_talk[8]\n",
    "        speaker = recommend_talk[2]\n",
    "        abstract = recommend_talk[4]\n",
    "        \n",
    "        dispatcher.utter_message(\"I would recommend you attend: {}\".format(title))\n",
    "\n",
    "\n",
    "        return [SlotSet(\"speaker\", speaker), SlotSet(\"length\",length), SlotSet(\"abstract\", abstract)]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store actions > actions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.4 Defining the domain\n",
    "\n",
    "Once we have the training data in place, we can define the domain of our assistant. A domain defines the environment in which the assistant operates - what user inputs it should expect to see, what actions it should be able to predict, what information the assistant should store throughout the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "- greet\n",
    "- goodbye\n",
    "- recommend_session\n",
    "- speaker\n",
    "- length\n",
    "- abstract\n",
    "- speaker+length\n",
    "- thanks\n",
    "- out-of-scope\n",
    "- inform\n",
    "\n",
    "\n",
    "\n",
    "slots:\n",
    "  relevant_audience:\n",
    "    type: text\n",
    "  venue:\n",
    "    type: unfeaturized\n",
    "  length:\n",
    "    type: unfeaturized\n",
    "  speaker:\n",
    "    type: unfeaturized\n",
    "  abstract:\n",
    "    type: unfeaturized\n",
    "    \n",
    "entities:\n",
    "- relevant_audience\n",
    "\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_thanks\n",
    "- utter_goodbye\n",
    "- utter_length\n",
    "- utter_abstract\n",
    "- utter_speaker\n",
    "- utter_ask_relevant_audience\n",
    "- utter_out_of_scope\n",
    "- utter_ask_other_questions\n",
    "- action_recommend_session\n",
    "\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "    - text: \"Hey! I am a conference assistant. I can help you find the sessions to attend, or answer conference-related questions.\"\n",
    "\n",
    "  utter_thanks:\n",
    "    - text: \"You are very welcome!\"\n",
    "\n",
    "  utter_goodbye:\n",
    "    - text: \"See you later\"\n",
    "  \n",
    "  utter_out_of_scope:\n",
    "    - text: \"Sorry, I can't help you with that\"\n",
    "  \n",
    "  utter_ask_other_questions:\n",
    "    - text: \"Would you like to know anything else?\"\n",
    "    \n",
    "  utter_ask_relevant_audience:\n",
    "    - text: \"What would be the relevant audience?\"\n",
    "  \n",
    "  utter_speaker:\n",
    "    - text: \"The speaker is {speaker}.\"\n",
    "  \n",
    "  utter_length:\n",
    "    - text: \"The session is {length}\"\n",
    "    \n",
    "  utter_abstract:\n",
    "    - text: \"{abstract}\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.5 Training the dialogue model\n",
    "\n",
    "We now have all the components necessary to train the dialogue management model. The code cell below will train the model using the defined policy and store the model in a specified location for us to test later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.policies import KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "def train_dialogue():\n",
    "    # loading our neatly defined training dialogues\n",
    "    agent = Agent(\"domain.yml\", policies=[MemoizationPolicy(), KerasPolicy(epochs=200, max_history = 6)])\n",
    "    training_data = agent.load_data('stories.md')\n",
    "\n",
    "\n",
    "    agent.train(\n",
    "        training_data)\n",
    "\n",
    "    agent.persist('models/dialogue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.6 Testing the dialogue model\n",
    "\n",
    "It's finally time for the most exciting part - testing the bot! Let's spin up the custom action server and we are ready to go. Open a new terminal and exacute the following command:\n",
    "\n",
    "**python -m rasa_core_sdk.endpoint --actions actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "import time\n",
    "\n",
    "def load_assistant():\n",
    "    messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "    interpreter = NaturalLanguageInterpreter.create(model_directory)\n",
    "    endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "    agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "\n",
    "    print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "    while True:\n",
    "        a = input()\n",
    "        if a == 'stop':\n",
    "            break\n",
    "        responses = agent.handle_text(a)\n",
    "        for response in responses:\n",
    "            print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.7 Adding stories with multi-intents\n",
    "\n",
    "Next, let's add a few stories with multi-intents. Such stories will follow a regular data format, the only thing is that we can include a couple of actions to be predicted by an assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "               \n",
    "## happy path all info 1               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "## happy path all info 2               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks    \n",
    "  \n",
    "\n",
    "## happy path all info 3               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks  \n",
    "\n",
    "\n",
    "## happy path no relevant audience            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session\n",
    "  - utter_ask_relevant_audience\n",
    "* inform{\"relevant_audience\":\"Data Scientists\"}\n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks \n",
    "  \n",
    "## multi-intents story1              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "## multi-intents story2              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.8 Adding out-of-scope inputs\n",
    "\n",
    "Finally, let's design a story with out-of-scope user inputs. Here, it's important to enable an assistant to take charge of the conversation and guide the user back to the initial conversation. In our case, an assistant will let the user know that it cannot deal with the out-of-scope request and will offer other questions to be asked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "## happy path all info 1               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "## happy path all info 2               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks    \n",
    "  \n",
    "\n",
    "## happy path all info 3               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks  \n",
    "\n",
    "\n",
    "## happy path no relevant audience            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session\n",
    "  - utter_ask_relevant_audience\n",
    "* inform{\"relevant_audience\":\"Data Scientists\"}\n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks \n",
    "\n",
    "  \n",
    "## multi-intents story1              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "## multi-intents story2              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "## multi-intents story2              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "## multi-intents story2              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "  \n",
    "## out-of-scope input story 1            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* out-of-scope\n",
    "  - utter_out_of_scope\n",
    "  - utter_ask_other_questions\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "## out-of-scope input story 2            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* out-of-scope\n",
    "  - utter_out_of_scope\n",
    "  - utter_ask_other_questions\n",
    "* thanks\n",
    "  - utter_thanks \n",
    "  \n",
    "## out-of-scope input story              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* out-of-scope\n",
    "  - utter_out_of_scope\n",
    "  - utter_ask_other_questions\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.9 Dialogue model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Another great way to see how good our dialogue model is, is to test it using evaluation scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python -m rasa_core.evaluate --core models/dialogue --stories stories.md -o results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# 3. Closing the feedback loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Developing an assistant is just one part of the process. Another very important part which defines a successful assistant is enabling your assistant to learn from real user feedback. In the last part of this workshop, we will cover two ways to improve your bots using real user feedback - using interactive learning and using the history of the conversations. We will also, connect our assistant to a custom webpage to see how it works in action! We will complete this part using the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 3.1. Improving the assistant using the interactive learning \n",
    "Interactive learning is a great way to improve your assistant and generate more training example by simply talking to your bot and providing feedback for all predictions it made. That is the main idea behind it - instead of responding right away, an assistant will tell you what it thinks it should do next and ask you for feedback. To start the interactive learning session, we will use a command line and use the following command:\n",
    "\n",
    "\n",
    "**python -m rasa_core.train interactive --core models/dialogue --nlu models/current/default/nlu --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 3.2. Storing conversation history \n",
    "Another way to improve your assistant is to observe real conversations between the users and a bot. To do so, we have to store the conversations in a storage first. In Rasa Core, tracker is responsible of keeping track of everything that happends throughout the conversation - user inputs, NLU model results, dialogue model predictions, etc. We can easily store all this data in a database for later use. In this step you will learn how to store this information in a Mongo tracker store. We will complete this step in a command line.\n",
    "\n",
    "First, we will setup a mongodb backend and store the conversaton history there. For that, we will start our assistant on a server using:  \n",
    "**python -m rasa_core.run -d models/dialogue -u models/current/default/nlu --port 5005  --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "##  3.3. Connecting the assistant to the outside world\n",
    "In the very last step of this workshop, you will learn how to connect your assistant to a custom UI which can be easily added to a website of your choice. The repository of this workshop contains a folder called *bot_ui* where you can find a very basic html webpage. We will add a UI code stored in a *ui.html* file and connect our assistant to it. We will complete this step using a text editor and a command line.\n",
    "\n",
    "After setting up the backed, we will start our assistant on a server and connect to the UI using:\n",
    "\n",
    "**python -m rasa_core.run -d models/dialogue -u models/current/default/nlu --port 5005  --endpoints endpoints.yml --credentials credentials.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# 4. Summary \n",
    "In this workshop, we covered some of the most important steps of the chatbot development and you should have a simple conference bot running your machine. There are so many things you can do to take this assistant to the whole new level! Here are some ideas for you:\n",
    "- Add new skills like:\n",
    "        show the session timetable \n",
    "        tell what is the next session at a specific venue   \n",
    "        connect with a speaker on social media  \n",
    "        recommend resources to learn more about the topic  \n",
    "        \n",
    "- Add new entities like date and time\n",
    "- Connect your assistant to the most popular messaging platforms like Facebook, Slack or Telegram\n",
    "\n",
    "Make sure to reference [Rasa official documentation](https://rasa.com/docs) or ask questions on the [Rasa Community Forum](https://forum.rasa.com) if you are in doubt! \n",
    "\n",
    "Most importantly, let me know what you came up with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "pt",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
