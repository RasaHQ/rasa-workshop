{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Building AI assistants that scale using machine learning and open source tools\n",
    "\n",
    "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaX3LNhGcAe1HnPZSuWS0oH6af0LJHXcH7If1sQgLCFAT1chNGFg)\n",
    "\n",
    "In this workshop, you will learn how to build your own conversational AI assistant using machine learning and real conversational data. The goal of this workshop is to walk you through the process of building an ML-powered assistant from scratch and build an actual assistant which you can improve later.\n",
    "\n",
    "\n",
    "There are no additional requirements to run this notebook, but if you encounter any issues or have more questions about the content included here, feel free send a message to an author of this exercise at juste@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## Construindo assistentes de IA que escalam usando aprendizado de máquina e ferramentas de código aberto\n",
    "\n",
    "! [texto alternativo] (https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaX3LNhGcAe1HnPZSuWS0oH6af0LJHXcH7If1sQgLCFAT1chNGFg)\n",
    "\n",
    "Neste workshop, você aprenderá como construir seu próprio assistente de IA de conversação usando aprendizado de máquina e dados reais de conversação. O objetivo deste workshop é guiá-lo através do processo de construção de um assistente de ML a partir do zero e construir um assistente real que você possa melhorar mais tarde.\n",
    "\n",
    "\n",
    "Não há requisitos adicionais para executar este notebook, mas se você encontrar quaisquer problemas ou tiver mais perguntas sobre o conteúdo incluído aqui, fique à vontade para enviar uma mensagem para um autor deste exercício em juste@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "During the course of this 3-hour workshop, you will go through each stage of the chatbot development and build an assistant capable of recommending talks to attend in this conference and answer the questions about the event. Below is an example conversation your assistant will be able to handle:\n",
    "\n",
    "U: Hello  \n",
    "A: Hello! I am a conference assistant ready to help you find talks to attend or anwers any questions you have.  \n",
    "U: What session would you recommend for Data Scientists today?  \n",
    "A: You can attend 'Building AI assistnats that scale using machine learning and open source tools' session!  \n",
    "U: Who is the speaker and how long is the session?  \n",
    "A: The speaker is Justina. The session is 3 hours long.  \n",
    "U: Thanks!  \n",
    "A: You are very welcome!  \n",
    "\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "# Durante o curso deste workshop de 3 horas, você passará por cada etapa do desenvolvimento do chatbot e criará um assistente capaz de recomendar palestras para participar desta conferência e responder às perguntas sobre o evento. Abaixo está um exemplo de conversa que seu assistente poderá manipular:\n",
    "\n",
    "U: Olá\n",
    "Um olá! Eu sou um assistente de conferência pronto para ajudá-lo a encontrar palestras para participar ou anwers quaisquer perguntas que você tem.\n",
    "U: Qual sessão você recomendaria para os cientistas de dados hoje?\n",
    "R: Você pode participar da sessão 'Building AI assistnats que escala usando aprendizado de máquina e ferramentas open source'!\n",
    "U: Quem é o orador e quanto tempo dura a sessão?\n",
    "A: O orador é Justina. A sessão dura 3 horas.\n",
    "U: Obrigado!\n",
    "A: Você é muito bem vindo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The workshop consists of the following stages:\n",
    "\n",
    "**0. Intro:**  \n",
    "    0.1 Setup and installation \n",
    "      \n",
    "**1. Stage 1: Natural language understanding:**  \n",
    "    1.1. Designing the happy path  \n",
    "    1.2. Generating the NLU training examples  \n",
    "    1.3. Designing the training pipeline  \n",
    "    1.4. Training the first NLU model  \n",
    "    1.5.  Handling out-of-scope inputs  \n",
    "    1.6. Adding sinonyms  \n",
    "    1.7. Adding multi-intents  \n",
    "    1.8. Re-training and thesting the updated NLU model  \n",
    "      \n",
    "**2. Stage 2: Dialogue management model:**  \n",
    "    2.1. Designing training stories  \n",
    "    2.2. Setting up the backend component  \n",
    "    2.3. Creating a custom action  \n",
    "    2.4. Defining the domain  \n",
    "    2.5. Training the dialogue model  \n",
    "    2.6. Testing the dialogue model   \n",
    "    2.7. Handling out-of-scope conversations  \n",
    "    2.8. Adding stories with multi-intents  \n",
    "    2.9. Evaluating dialogue model  \n",
    "      \n",
    "**3. Stage 3: Closing the feedback loop:**  \n",
    "    3.1. Improving the assistant using the interactive learning   \n",
    "    3.2. Storing conversation history    \n",
    "    3.3. Connecting the assistant to the outside world  \n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "# O workshop consiste nas seguintes etapas:\n",
    "\n",
    "**0. Introdução:**\n",
    "    0.1 Configuração e instalação\n",
    "      \n",
    "**1. Estágio 1: compreensão da linguagem natural:**\n",
    "    1.1. Criando o caminho feliz\n",
    "    1.2. Gerando os Exemplos de Treinamento da NLU\n",
    "    1.3. Projetando o pipeline de treinamento\n",
    "    1.4. Treinando o primeiro modelo NLU\n",
    "    1.5. Manipulando Entradas Fora do Escopo\n",
    "    1.6. Adicionando sinônimos\n",
    "    1.7. Adicionando multi-intenções\n",
    "    1.8. Re-treinando e testando o modelo NLU atualizado\n",
    "      \n",
    "**2. Etapa 2: Modelo de gerenciamento de diálogo:**\n",
    "    2.1. Criando histórias de treinamento\n",
    "    2.2. Configurando o componente backend\n",
    "    2.3. Criando uma ação customizada\n",
    "    2.4. Definindo o domínio\n",
    "    2.5. Treinando o modelo de diálogo\n",
    "    2.6. Testando o modelo de diálogo\n",
    "    2.7. Lidando com conversas fora do escopo\n",
    "    2.8. Adicionando histórias com várias intenções\n",
    "    2.9. Avaliação do modelo de diálogo\n",
    "      \n",
    "**3. Estágio 3: fechando o ciclo de feedback:**\n",
    "    3.1. Melhorando o assistente usando o aprendizado interativo\n",
    "    3.2. Armazenando histórico de conversas\n",
    "    3.3. Conectando o assistente ao mundo exterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 0. Intro\n",
    "In this section, we will install all the necessary dependencies needed to successfully run this exercise.\n",
    "### 0.1. Setup and installation\n",
    "The best way to insall the necessary modules is to use the requirements.txt file. After creating a virtual environment, run:\n",
    "\n",
    "**pip install -r requirements.txt**\n",
    "\n",
    "Throughout this workshop, we will use only open source tools. The code block below checks if Rasa NLU and Rasa Core have been installed suffessfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 0. Introdução\n",
    "Nesta seção, instalaremos todas as dependências necessárias para executar este exercício com sucesso.\n",
    "### 0.1. Instalação e instalação\n",
    "A melhor maneira de instalar os módulos necessários é usar o arquivo requirements.txt. Depois de criar um ambiente virtual, execute:\n",
    "\n",
    "**pip install -r requirements.txt**\n",
    "\n",
    "Ao longo deste workshop, usaremos apenas ferramentas de código aberto. O bloco de código abaixo verifica se o Rasa NLU e o Rasa Core foram instalados sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa_nlu.__version__, rasa_core.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1. Natural Language Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 1. Compreensão da Linguagem Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "In this section, you will enable your assistant to understand the user inputs by building a Rasa NLU model. This model will take unstructured user inputs and extract structured data in a form of intents and entities:  \n",
    "- *intent* - a label which represents the overall intention of the user 's input\n",
    "- *entity* - important detail which an assistant should extract and use to steer the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Nesta seção, você permitirá que seu assistente entenda as entradas do usuário construindo um modelo Rasa NLU. Esse modelo usará entradas não estruturadas do usuário e extrairá dados estruturados em uma forma de intenções e entidades:\n",
    "- *intent* - um rótulo que representa a intenção geral da entrada do usuário\n",
    "- *entidade* - detalhe importante que um assistente deve extrair e usar para orientar a conversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 1.1. Designing a happy path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "### 1.1. Criando um caminho feliz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "A good starting point is to define a happy path first. A happy path is a conversation flow where the user provides all the required information and allows the assistant to lead the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Um bom ponto de partida é definir um caminho feliz primeiro. Um caminho feliz é um fluxo de conversa em que o usuário fornece todas as informações necessárias e permite que o assistente conduza a conversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 1.2. Designing the NLU training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "### 1.2. Projetando os dados de treinamento da NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "To train the NLU model you will need some labeled training data. Rasa NLU training data samples consist of the following components:  \n",
    "- intent label which starts with a prefix *\n",
    "- examples of text inputs which correspond to that label\n",
    "- entities which follow the format *[entity_value] (entity_label)*\n",
    "\n",
    "We will start by generating some training data examples by hand. For a completed data file check out the *helper_files/nlu_data.md* in the repository of this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Para treinar o modelo NLU, você precisará de alguns dados de treinamento rotulados. As amostras de dados de treinamento Rasa NLU consistem dos seguintes componentes:\n",
    "- etiqueta de intenção que começa com um prefixo *- exemplos de entradas de texto que correspondem a esse rótulo\n",
    "- entidades que seguem o formato* [entidade _valor] (entidade_ rótulo) *Vamos começar gerando alguns exemplos de dados de treinamento manualmente. Para um arquivo de dados completo, confira o* helper _files / nlu_ data.md * no repositório deste exercício."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience)\n",
    "- for [product](relevant_audience) people\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "\n",
    "## 1.3 Designing the training pipeline\n",
    "\n",
    "Once the training data is ready, we can define the NLU model. We can do that by constructing the processing pipeline which defines how structured data will be extracted from unstructured user inputs: how the sentences will be tokenized, what intent classifier will be used, what entity extraction model will be used, etc. Each component in a training pipeline is trained one after another and can take inputs from the previously defined component as well as pass some information to subsequent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 1.3 Criando o pipeline de treinamento\n",
    "\n",
    "Quando os dados de treinamento estiverem prontos, podemos definir o modelo NLU. Podemos fazer isso construindo o pipeline de processamento que define como os dados estruturados serão extraídos das entradas não estruturadas do usuário: como as sentenças serão tokenizadas, qual classificador de intenção será usado, qual modelo de extração de entidade será usado, etc. Cada componente em um O pipeline de treinamento é treinado um após o outro e pode receber entradas do componente previamente definido, assim como passar algumas informações para os subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"             # splits the sentence into tokens\n",
    "- name: \"ner_crf\"                   # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_count_vectors\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_tensorflow_embedding\"   # intent classifier\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1.4 Training the first Rasa NLU Model\n",
    "Now, we're going to train the NLU model to recognise user inputs, so that when you send a message like \"hello\" to your bot, it will recognise this as a \"greet\" intent. Let's define the training function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 1.4 Treinando o primeiro modelo Rasa NLU\n",
    "Agora, vamos treinar o modelo NLU para reconhecer as entradas do usuário, para que quando você enviar uma mensagem como \"olá\" para o seu bot, ele reconheça isso como uma intenção de \"cumprimentar\". Vamos definir a função de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "def train_nlu_model():\n",
    "    # loading the nlu training samples\n",
    "    training_data = load_data(\"nlu.md\")\n",
    "\n",
    "    # trainer to educate our pipeline\n",
    "    trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "    # train the model!\n",
    "    interpreter = trainer.train(training_data)\n",
    "\n",
    "    # store it for future use\n",
    "    model_directory = trainer.persist(\"./models/current\", fixed_model_name=\"nlu\")\n",
    "    \n",
    "    return interpreter, model_directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Finally, let's train the model using the previously defined data and model configuration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Finalmente, vamos treinar o modelo usando dados previamente definidos e configuração do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Testing the model\n",
    "\n",
    "We have trained the first version of our NLU model! Let's test it on various inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## Testando o modelo\n",
    "\n",
    "Nós treinamos a primeira versão do nosso modelo NLU! Vamos testá-lo em várias entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper function to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))\n",
    "\n",
    "#change the input message with your prefered inputs\n",
    "input_message = \"What talks would you recommend to data scientists?\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Handling out-of-scope inputs\n",
    "When dealing with conversational AI, out-of-scope user inputs are very common challenge. These inputs represent the user requests which have nothing to do with the assistant's job. While it's very challenging to provide a sensible answer to each out-of-scope input, it's important to enable your assistant to identify such inputs and guide the user back to the conversation. First, let's enable our assistant to identify out-of-scope inputs. To do that, we will add a new intent called *out-of-scope* to our training dataset and provde some corresponding inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## Gerenciando entradas fora do escopo\n",
    "Ao lidar com a IA conversacional, as entradas do usuário fora do escopo são um desafio muito comum. Essas entradas representam as solicitações do usuário que não têm nada a ver com o trabalho do assistente. Embora seja muito desafiador fornecer uma resposta sensata a cada entrada fora do escopo, é importante permitir que seu assistente identifique essas entradas e guie o usuário de volta à conversa. Primeiro, vamos permitir que nosso assistente identifique entradas fora do escopo. Para fazer isso, adicionaremos um novo intento chamado *fora do escopo* ao nosso conjunto de dados de treinamento e forneceremos algumas entradas correspondentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Let's retrain the model and see how it deals with out-of-scope inputs now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Vamos treinar novamente o modelo e ver como ele lida com as entradas fora do escopo agora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"I want pizza\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1.6 Adding synonyms\n",
    "\n",
    "Synonyms are a very useful Rasa NLU feature which maps extracted entities to the same name. It's used when some extracted values have to be normalised so that they could be used to query the database or make an API call. In our example, the occupation of the relevant audience is a good candidate for the synonym because users can provide the same occupation in a variety of different ways (for example, Machine Learning and ML). Let's update our training examples with synonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 1.6 Adicionando sinônimos\n",
    "\n",
    "Sinônimos são um recurso RUU muito útil que mapeia entidades extraídas com o mesmo nome. É usado quando alguns valores extraídos precisam ser normalizados para que possam ser usados ​​para consultar o banco de dados ou fazer uma chamada de API. Em nosso exemplo, a ocupação do público relevante é um bom candidato para o sinônimo, pois os usuários podem fornecer a mesma ocupação de várias maneiras diferentes (por exemplo, Machine Learning e ML). Vamos atualizar nossos exemplos de treinamento com sinônimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience:ML) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience:ML) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience:ML)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "To train the NLU model with synonyms, we have to add the synonyms component to the model pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Para treinar o modelo NLU com sinônimos, temos que adicionar o componente de sinônimos ao pipeline do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"             # splits the sentence into tokens\n",
    "- name: \"ner_crf\"                   # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_count_vectors\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_tensorflow_embedding\"   # intent classifier\n",
    "- name: \"ner_synonyms\"     #trains synonyms component\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Now, let's retrain the NLU model and test the performace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Agora, vamos treinar novamente o modelo NLU e testar o desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "See how 'machine learning engineers' now gets mapped to 'ML':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Veja como os 'engenheiros de aprendizado de máquina' agora são mapeados para 'ML':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"For machine learning engineers\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1.7 Implementing multi-intents\n",
    "\n",
    "The NLU model we have built so far works pretty well, but it only supports inputs with only one intent per user input. In this step, we will use a tensorflow embedding model to enable the assistant to recognise multi-intents - more than one intention per user input. Let's start by defining multi-intents in our training data. Multi-intents are defined in a very similar way as regular intents, the only difference is that the label names consists of intent tokens and a character of your choice that separates them, for example **intent_token1+intent_token2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 1.7 Implementando multi-intenções\n",
    "\n",
    "O modelo NLU que construímos até agora funciona muito bem, mas suporta apenas entradas com apenas uma intenção por entrada de usuário. Nesta etapa, usaremos um modelo de incorporação de tensorflow para permitir que o assistente reconheça múltiplas intenções - mais de uma intenção por entrada de usuário. Vamos começar definindo as múltiplas intenções em nossos dados de treinamento. Multi-intenções são definidas de maneira muito semelhante às intenções regulares, a única diferença é que os nomes dos rótulos consistem em tokens de intenção e um caractere de sua escolha que os separa, por exemplo, **intent_token1 + intent_token2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience:ML) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience:ML) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience:ML)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\n",
    "\n",
    "## intent:speaker+length\n",
    " - Who is the presenter? Also, how long is the talk?\n",
    " - Who is the speaker and how long is the session?\n",
    " - Is the session long and who is presenting?\n",
    " - Do you know who is the presenter of the session? And how long is the session?\n",
    " - Is the talk long and who is presenting?\n",
    " - Who is the speaker? And how long is the talk?\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Next, let's modify the configuration of the model pipeline to use the tensorflow_embedding model with multi-intent support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Em seguida, vamos modificar a configuração do pipeline de modelo para usar o modelo tensorflow_embedding com suporte a várias intenções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"             # splits the sentence into tokens\n",
    "- name: \"ner_crf\"                   # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_count_vectors\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_tensorflow_embedding\"   # intent classifier\n",
    "  intent_tokenization_flag: true # sets multi-intent tokenization\n",
    "  intent_split_symbol: \"+\"       # sets which symbol should be used for tokenization\n",
    "- name: \"ner_synonyms\"   # trains synonyms component \n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Let's retrain the model with the new pipeline and test the performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Vamos treinar novamente o modelo com o novo pipeline e testar o desempenho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "See how a two-question input now gets recognised as a multi-intent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Veja como uma entrada de duas perguntas agora é reconhecida como uma múltipla intenção:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Who is the speakers and how long is the session?\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1.8 Evaluating the NLU model\n",
    "\n",
    "\n",
    "Testing the model on various inputs is a good way to get high-level insights into the performance of the model. However, it's a time consuming and quite a tedious way of testing. Instead of evaluating the model by hand, it can also be evaluated on a test data set (though for simplicity we are going to use the same for test and train):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 1.8 Avaliando o modelo NLU\n",
    "\n",
    "\n",
    "Testar o modelo em várias entradas é uma boa maneira de obter insights de alto nível sobre o desempenho do modelo. No entanto, é uma maneira demorada e tediosa de testar. Em vez de avaliar o modelo manualmente, ele também pode ser avaliado em um conjunto de dados de teste (embora, por simplicidade, usemos o mesmo para teste e treinamento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rasa_nlu.evaluate import run_evaluation\n",
    "import IPython\n",
    "from IPython import display\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Congratulations! You have just implemented the natural language understanding part of your assistant which means that your assistant can now understand you. In the second part of this workshop, we will delve into the next stage of the chatbot development - dialogue management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Parabéns! Você acaba de implementar a parte de compreensão de linguagem natural de seu assistente, o que significa que seu assistente agora pode entender você. Na segunda parte deste workshop, vamos nos aprofundar na próxima etapa do desenvolvimento do chatbot - gerenciamento de diálogos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# 2. Dialogue Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "# 2. Gerenciamento de Diálogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "In this section of this workshop you will build a machine learning-based dialogue model which will enable your assistant to decide on how to respond to user inputs based on the state of the conversation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Nesta seção deste workshop, você construirá um modelo de diálogo baseado em aprendizado de máquina que permitirá ao seu assistente decidir como responder às entradas do usuário com base no estado da conversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.1 Designing the training stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 2.1 Criando as histórias de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Let's start with generating the training data. Rasa Core models learn by observing real conversational data between the user and the assistant. The only important thing is that this data has to be converted into the Rasa Core format: user inputs have to be expressed as corresponding intents (and entities where necessary) while the responses of the assistant are expressed as action names. Each training story follows the format:  \n",
    "- the story starts with a story name which has a prefix ##  \n",
    "- intents, corresponding to user inputs, start with *  \n",
    "- if NLU model extracts entities which should influence the predictions of the dialogue model, they have to be included in the stories using the following format: * intent{'entity_name':\"entity_value\"}  \n",
    "- the responses of the bot start with -  \n",
    "- the story ends with an empty line which marks the end of the story\n",
    "\n",
    "In the next step of this tutorial, we will generate some training stories to cover the happy path. To see a complete training data example, check out the **data/stories.md** file of this repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Vamos começar gerando os dados de treinamento. Os modelos Rasa Core aprendem observando dados reais de conversação entre o usuário e o assistente. A única coisa importante é que esses dados devem ser convertidos no formato Rasa Core: as entradas do usuário devem ser expressas como intenções correspondentes (e entidades, quando necessário), enquanto as respostas do assistente são expressas como nomes de ação. Cada história de treinamento segue o formato:\n",
    "- a história começa com um nome de história que tem um prefixo ##\n",
    "- intenções, correspondentes às entradas do usuário, começam com *- se o modelo NLU extrai entidades que devem influenciar as previsões do modelo de diálogo, elas devem ser incluídas nas histórias usando o seguinte formato:* intent {'entity _name': \"entidade_ value\"}\n",
    "- as respostas do bot começam com -\n",
    "- a história termina com uma linha vazia que marca o fim da história\n",
    "\n",
    "Na próxima etapa deste tutorial, vamos gerar algumas histórias de treinamento para cobrir o caminho feliz. Para ver um exemplo completo de dados de treinamento, confira o arquivo **data / stories.md** deste repositório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "## happy path all info 1               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "## happy path all info 2               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks    \n",
    "  \n",
    "\n",
    "## happy path all info 3               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks  \n",
    "\n",
    "\n",
    "## happy path no relevant audience            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session\n",
    "  - utter_ask_relevant_audience\n",
    "* inform{\"relevant_audience\":\"Data Scientists\"}\n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.2 Setting up the backend component\n",
    "\n",
    "We want to make our assistant engaging and fun. For that reason, we will enable it to answer the questions using the real data stored in a SQL database. For this exercise, the assistant will be able to pull information about the conference agenda, talks, and speakers. Let's take a look at how the data in a SQL database looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 2.2 Configurando o componente backend\n",
    "\n",
    "Queremos tornar nossa assistente envolvente e divertida. Por esse motivo, permitiremos que ele responda às perguntas usando os dados reais armazenados em um banco de dados SQL. Para este exercício, o assistente poderá obter informações sobre a agenda, palestras e palestrantes da conferência. Vamos dar uma olhada em como os dados em um banco de dados SQL se parece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as lite\n",
    "import pandas as pd\n",
    "\n",
    "conn = lite.connect('ConfDB.db')\n",
    "data = pd.read_sql_query(\"SELECT * FROM agenda LIMIT 10\", conn)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.3 Creating custom action\n",
    "\n",
    "We are going to use the backend integration to enable our assistant to fetch the relevant data based on user's queries. For that, we will create custom actions which, when predicted, will collect necessary data and use it to steer the conversation further:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 2.3 Criando uma ação personalizada\n",
    "\n",
    "Vamos usar a integração de back-end para permitir que nosso assistente obtenha os dados relevantes com base nas consultas do usuário. Para isso, criaremos ações personalizadas que, quando previstas, coletarão os dados necessários e os usarão para direcionar a conversa ainda mais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = \"\"\"\n",
    "from rasa_core_sdk import Action\n",
    "from rasa_core_sdk.events import SlotSet\n",
    "import sqlite3 as lite\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "class ActionRecommendTalk(Action):\n",
    "    def name(self):\n",
    "        return \"action_recommend_session\"\n",
    "        \n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        conn = lite.connect('ConfDB.db')\n",
    "        cur = conn.cursor()\n",
    "        relevant_audience = tracker.get_slot('relevant_audience')\n",
    "        cur.execute(\"SELECT * FROM agenda where relevant_audience like '%{}%'\".format(relevant_audience))\n",
    "\n",
    "        rows = cur.fetchall()\n",
    "        ind = random.randint(0,len(rows))\n",
    "        recommend_talk = list(rows[ind])\n",
    "        title = recommend_talk[0]\n",
    "        length = recommend_talk[8]\n",
    "        speaker = recommend_talk[2]\n",
    "        abstract = recommend_talk[4]\n",
    "        \n",
    "        dispatcher.utter_message(\"I would recommend you attend: {}\".format(title))\n",
    "\n",
    "\n",
    "        return [SlotSet(\"speaker\", speaker), SlotSet(\"length\",length), SlotSet(\"abstract\", abstract)]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store actions > actions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.4 Defining the domain\n",
    "\n",
    "Once we have the training data in place, we can define the domain of our assistant. A domain defines the environment in which the assistant operates - what user inputs it should expect to see, what actions it should be able to predict, what information the assistant should store throughout the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 2.4 Definindo o domínio\n",
    "\n",
    "Assim que tivermos os dados de treinamento, podemos definir o domínio de nosso assistente. Um domínio define o ambiente no qual o assistente opera - quais entradas do usuário ele deve esperar ver, quais ações ele deve ser capaz de prever, quais informações o assistente deve armazenar durante toda a conversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "- greet\n",
    "- goodbye\n",
    "- recommend_session\n",
    "- speaker\n",
    "- length\n",
    "- abstract\n",
    "- speaker+length\n",
    "- thanks\n",
    "- out-of-scope\n",
    "- inform\n",
    "\n",
    "\n",
    "\n",
    "slots:\n",
    "  relevant_audience:\n",
    "    type: text\n",
    "  venue:\n",
    "    type: unfeaturized\n",
    "  length:\n",
    "    type: unfeaturized\n",
    "  speaker:\n",
    "    type: unfeaturized\n",
    "  abstract:\n",
    "    type: unfeaturized\n",
    "    \n",
    "entities:\n",
    "- relevant_audience\n",
    "\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_thanks\n",
    "- utter_goodbye\n",
    "- utter_length\n",
    "- utter_abstract\n",
    "- utter_speaker\n",
    "- utter_ask_relevant_audience\n",
    "- utter_out_of_scope\n",
    "- utter_ask_other_questions\n",
    "- action_recommend_session\n",
    "\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "    - text: \"Hey! I am a conference assistant. I can help you find the sessions to attend, or answer conference-related questions.\"\n",
    "\n",
    "  utter_thanks:\n",
    "    - text: \"You are very welcome!\"\n",
    "\n",
    "  utter_goodbye:\n",
    "    - text: \"See you later\"\n",
    "  \n",
    "  utter_out_of_scope:\n",
    "    - text: \"Sorry, I can't help you with that\"\n",
    "  \n",
    "  utter_ask_other_questions:\n",
    "    - text: \"Would you like to know anything else?\"\n",
    "    \n",
    "  utter_ask_relevant_audience:\n",
    "    - text: \"What would be the relevant audience?\"\n",
    "  \n",
    "  utter_speaker:\n",
    "    - text: \"The speaker is {speaker}.\"\n",
    "  \n",
    "  utter_length:\n",
    "    - text: \"The session is {length}\"\n",
    "    \n",
    "  utter_abstract:\n",
    "    - text: \"{abstract}\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.5 Training the dialogue model\n",
    "\n",
    "We now have all the components necessary to train the dialogue management model. The code cell below will train the model using the defined policy and store the model in a specified location for us to test later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 2.5 Treinando o modelo de diálogo\n",
    "\n",
    "Agora temos todos os componentes necessários para treinar o modelo de gerenciamento de diálogos. A célula de código abaixo irá treinar o modelo usando a política definida e armazenar o modelo em um local especificado para que possamos testar mais tarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.policies import KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "def train_dialogue():\n",
    "    # loading our neatly defined training dialogues\n",
    "    agent = Agent(\"domain.yml\", policies=[MemoizationPolicy(), KerasPolicy(epochs=200, max_history = 6)])\n",
    "    training_data = agent.load_data('stories.md')\n",
    "\n",
    "\n",
    "    agent.train(\n",
    "        training_data)\n",
    "\n",
    "    agent.persist('models/dialogue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.6 Testing the dialogue model\n",
    "\n",
    "It's finally time for the most exciting part - testing the bot! Let's spin up the custom action server and we are ready to go. Open a new terminal and exacute the following command:\n",
    "\n",
    "**python -m rasa_core_sdk.endpoint --actions actions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 2.6 Testando o modelo de diálogo\n",
    "\n",
    "Finalmente chegou a hora da parte mais emocionante - testar o bot! Vamos acelerar o servidor de ações personalizadas e estamos prontos para começar. Abra um novo terminal e exija o seguinte comando:\n",
    "\n",
    "**python -m rasa_core_sdk.endpoint --actions actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "import time\n",
    "\n",
    "def load_assistant():\n",
    "    messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "    interpreter = NaturalLanguageInterpreter.create(model_directory)\n",
    "    endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "    agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "\n",
    "    print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "    while True:\n",
    "        a = input()\n",
    "        if a == 'stop':\n",
    "            break\n",
    "        responses = agent.handle_text(a)\n",
    "        for response in responses:\n",
    "            print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.7 Adding stories with multi-intents\n",
    "\n",
    "Next, let's add a few stories with multi-intents. Such stories will follow a regular data format, the only thing is that we can include a couple of actions to be predicted by an assistant:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.7 Adicionando histórias com várias intenções\n",
    "\n",
    "Em seguida, vamos adicionar algumas histórias com várias intenções. Tais histórias seguirão um formato de dados regular, a única coisa é que podemos incluir algumas ações a serem previstas por um assistente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 2.7 Adicionando histórias com várias intenções\n",
    "\n",
    "Em seguida, lettuce some stories with several intenções. Tais datas em um formato de dados regular, a única coisa que é possível incluir várias ações que são previstas por um assistente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "               \n",
    "## happy path all info 1               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "## happy path all info 2               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks    \n",
    "  \n",
    "\n",
    "## happy path all info 3               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks  \n",
    "\n",
    "\n",
    "## happy path no relevant audience            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session\n",
    "  - utter_ask_relevant_audience\n",
    "* inform{\"relevant_audience\":\"Data Scientists\"}\n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks \n",
    "  \n",
    "## multi-intents story1              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "## multi-intents story2              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.8 Adding out-of-scope inputs\n",
    "\n",
    "Finally, let's design a story with out-of-scope user inputs. Here, it's important to enable an assistant to take charge of the conversation and guide the user back to the initial conversation. In our case, an assistant will let the user know that it cannot deal with the out-of-scope request and will offer other questions to be asked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "## happy path all info 1               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "## happy path all info 2               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks    \n",
    "  \n",
    "\n",
    "## happy path all info 3               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* length\n",
    "  - utter_length\n",
    "* thanks\n",
    "  - utter_thanks  \n",
    "\n",
    "\n",
    "## happy path no relevant audience            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session\n",
    "  - utter_ask_relevant_audience\n",
    "* inform{\"relevant_audience\":\"Data Scientists\"}\n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* length\n",
    "  - utter_length\n",
    "* speaker\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks \n",
    "\n",
    "  \n",
    "## multi-intents story1              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "## multi-intents story2              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "## multi-intents story2              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "## multi-intents story2              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* speaker+length\n",
    "  - utter_length\n",
    "  - utter_speaker\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "  \n",
    "  \n",
    "## out-of-scope input story 1            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* out-of-scope\n",
    "  - utter_out_of_scope\n",
    "  - utter_ask_other_questions\n",
    "* abstract\n",
    "  - utter_abstract\n",
    "* thanks\n",
    "  - utter_thanks\n",
    "  \n",
    "## out-of-scope input story 2            \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* out-of-scope\n",
    "  - utter_out_of_scope\n",
    "  - utter_ask_other_questions\n",
    "* thanks\n",
    "  - utter_thanks \n",
    "  \n",
    "## out-of-scope input story              \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* recommend_session{\"relevant_audience\":\"Data Scientists\"}               \n",
    "  - action_recommend_session\n",
    "  - slot{\"speaker\":\"Justina\"}\n",
    "  - slot{\"length\":\"5 min\"}\n",
    "  - slot{\"abstract\":\"Workshop on chatbots\"}\n",
    "* out-of-scope\n",
    "  - utter_out_of_scope\n",
    "  - utter_ask_other_questions\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2.9 Dialogue model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 2.9 Avaliação do modelo de diálogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Another great way to see how good our dialogue model is, is to test it using evaluation scripts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Outra ótima maneira de ver como nosso modelo de diálogo é bom é testá-lo usando scripts de avaliação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python -m rasa_core.evaluate --core models/dialogue --stories stories.md -o results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# 3. Closing the feedback loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "# 3. Fechando o ciclo de feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Developing an assistant is just one part of the process. Another very important part which defines a successful assistant is enabling your assistant to learn from real user feedback. In the last part of this workshop, we will cover two ways to improve your bots using real user feedback - using interactive learning and using the history of the conversations. We will also, connect our assistant to a custom webpage to see how it works in action! We will complete this part using the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Desenvolver um assistente é apenas uma parte do processo. Outra parte muito importante que define um assistente de sucesso é permitir que seu assistente aprenda com o feedback real do usuário. Na última parte deste workshop, abordaremos duas maneiras de melhorar seus bots usando o feedback real do usuário - usando o aprendizado interativo e usando o histórico das conversas. Nós também conectaremos nosso assistente a uma página da Web personalizada para ver como ela funciona em ação! Nós completaremos esta parte usando a linha de comando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 3.1. Improving the assistant using the interactive learning \n",
    "Interactive learning is a great way to improve your assistant and generate more training example by simply talking to your bot and providing feedback for all predictions it made. That is the main idea behind it - instead of responding right away, an assistant will tell you what it thinks it should do next and ask you for feedback. To start the interactive learning session, we will use a command line and use the following command:\n",
    "\n",
    "\n",
    "**python -m rasa_core.train interactive --core models/dialogue --nlu models/current/default/nlu --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 3.1. Melhorando o assistente usando o aprendizado interativo\n",
    "O aprendizado interativo é uma ótima maneira de melhorar seu assistente e gerar mais exemplos de treinamento simplesmente conversando com seu bot e fornecendo feedback para todas as previsões que ele fez. Essa é a idéia principal por trás disso - em vez de responder imediatamente, um assistente lhe dirá o que acha que deve fazer em seguida e pedir um feedback. Para iniciar a sessão de aprendizado interativo, usaremos uma linha de comando e usaremos o seguinte comando:\n",
    "\n",
    "\n",
    "**python -m rasa_core.train interactive --modelos de core / dialog --nlu models / current / default / nll --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 3.2. Storing conversation history \n",
    "Another way to improve your assistant is to observe real conversations between the users and a bot. To do so, we have to store the conversations in a storage first. In Rasa Core, tracker is responsible of keeping track of everything that happends throughout the conversation - user inputs, NLU model results, dialogue model predictions, etc. We can easily store all this data in a database for later use. In this step you will learn how to store this information in a Mongo tracker store. We will complete this step in a command line.\n",
    "\n",
    "First, we will setup a mongodb backend and store the conversaton history there. For that, we will start our assistant on a server using:  \n",
    "**python -m rasa_core.run -d models/dialogue -u models/current/default/nlu --port 5005  --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 3.2. Armazenando histórico de conversas\n",
    "Outra maneira de melhorar seu assistente é observar conversas reais entre os usuários e um bot. Para fazer isso, temos que armazenar as conversas em um armazenamento primeiro. No Rasa Core, o rastreador é responsável por acompanhar tudo o que acontece durante a conversa - entradas do usuário, resultados do modelo NLU, previsões de modelos de diálogo, etc. Podemos armazenar facilmente todos esses dados em um banco de dados para uso posterior. Nesta etapa, você aprenderá como armazenar essas informações em uma loja de rastreador Mongo. Nós completaremos este passo em uma linha de comando.\n",
    "\n",
    "Primeiro, vamos configurar um backend mongodb e armazenar o histórico de conversação lá. Para isso, vamos iniciar nosso assistente em um servidor usando:\n",
    "**python -m rasa_core.run -d models / diálogo -u models / current / default / nll --port 5005 --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "##  3.3. Connecting the assistant to the outside world\n",
    "In the very last step of this workshop, you will learn how to connect your assistant to a custom UI which can be easily added to a website of your choice. The repository of this workshop contains a folder called *bot_ui* where you can find a very basic html webpage. We will add a UI code stored in a *ui.html* file and connect our assistant to it. We will complete this step using a text editor and a command line.\n",
    "\n",
    "After setting up the backed, we will start our assistant on a server and connect to the UI using:\n",
    "\n",
    "**python -m rasa_core.run -d models/dialogue -u models/current/default/nlu --port 5005  --endpoints endpoints.yml --credentials credentials.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## 3.3. Conectando o assistente ao mundo exterior\n",
    "Na última etapa deste workshop, você aprenderá a conectar seu assistente a uma interface de usuário personalizada, que pode ser facilmente adicionada a um site de sua escolha. O repositório deste workshop contém uma pasta chamada *bot_ui* onde você pode encontrar uma página html bem básica. Vamos adicionar um código da interface do usuário armazenado em um arquivo *ui.html* e conectar nosso assistente a ele. Vamos concluir esta etapa usando um editor de texto e uma linha de comando.\n",
    "\n",
    "Depois de configurar o backup, iniciaremos nosso assistente em um servidor e nos conectaremos à interface do usuário usando:\n",
    "\n",
    "**python -m rasa_core.run -d models / diálogo -u models / current / default / nll --port 5005 --endpoints endpoints.yml --credentials credentials.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# 4. Summary \n",
    "In this workshop, we covered some of the most important steps of the chatbot development and you should have a simple conference bot running your machine. There are so many things you can do to take this assistant to the whole new level! Here are some ideas for you:\n",
    "- Add new skills like:\n",
    "        show the session timetable \n",
    "        tell what is the next session at a specific venue   \n",
    "        connect with a speaker on social media  \n",
    "        recommend resources to learn more about the topic  \n",
    "        \n",
    "- Add new entities like date and time\n",
    "- Connect your assistant to the most popular messaging platforms like Facebook, Slack or Telegram\n",
    "\n",
    "Make sure to reference [Rasa official documentation](https://rasa.com/docs) or ask questions on the [Rasa Community Forum](https://forum.rasa.com) if you are in doubt! \n",
    "\n",
    "Most importantly, let me know what you came up with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "# 4. Resumo\n",
    "Neste workshop, cobrimos algumas das etapas mais importantes do desenvolvimento do chatbot e você deve ter um simples bot de conferência executando sua máquina. Há tantas coisas que você pode fazer para levar este assistente a todo o novo nível! Aqui estão algumas idéias para você:\n",
    "- Adicione novas habilidades como:\n",
    "        mostre o calendário da sessão\n",
    "        diga qual é a próxima sessão em um local específico\n",
    "        conectar-se com um alto-falante nas mídias sociais\n",
    "        recomendar recursos para aprender mais sobre o tópico\n",
    "        \n",
    "- Adicionar novas entidades, como data e hora\n",
    "- Conecte seu assistente às plataformas de mensagens mais populares, como Facebook, Slack ou Telegram\n",
    "\n",
    "Certifique-se de referenciar [documentação oficial do Rasa] (https://rasa.com/docs) ou fazer perguntas no [Fórum da Comunidade Rasa] (https://forum.rasa.com) se você estiver em dúvida!\n",
    "\n",
    "Mais importante, deixe-me saber o que você veio com!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "pt"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "pt",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
