{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building AI assistants that scale using machine learning and open source tools\n",
    "\n",
    "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaX3LNhGcAe1HnPZSuWS0oH6af0LJHXcH7If1sQgLCFAT1chNGFg)\n",
    "\n",
    "In this workshop, you will learn how to build your own conversational AI assistant using machine learning and real conversational data. The goal of this workshop is to walk you through the process of building an ML-powered assistant from scratch and build an actual assistant which you can improve later.\n",
    "\n",
    "\n",
    "There are no additional requirements to run this notebook, but if you encounter any issues or have more questions about the content included here, feel free send a message to an author of this exercise at juste@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the course of this 3-hour workshop, you will go through each stage of the chatbot development and build an assistant capable of recommending talks to attend in this conference and answer the questions about the event. Below is an example conversation your assistant will be able to handle:\n",
    "\n",
    "U: Hello  \n",
    "A: Hello! I am a conference assistant ready to help you find talks to attend or anwers any questions you have.  \n",
    "U: What session would you recommend for Data Scientists today?  \n",
    "A: You can attend 'Building AI assistnats that scale using machine learning and open source tools' session!  \n",
    "U: Who is the speaker and how long is the session?  \n",
    "A: The speaker is Justina. The session is 3 hours long.  \n",
    "U: Thanks!  \n",
    "A: You are very welcome!  \n",
    "\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workshop consists of the following stages:\n",
    "\n",
    "**0. Intro:**  \n",
    "    0.1 Setup and installation \n",
    "      \n",
    "**1. Stage 1: Natural language understanding:**  \n",
    "    1.1. Designing the happy path  \n",
    "    1.2. Generating the NLU training examples  \n",
    "    1.3. Designing the training pipeline  \n",
    "    1.4. Training the first NLU model  \n",
    "    1.5.  Handling out-of-scope inputs  \n",
    "    1.6. Adding sinonyms  \n",
    "    1.7. Adding multi-intents  \n",
    "    1.8. Re-training and thesting the updated NLU model  \n",
    "      \n",
    "**2. Stage 2: Dialogue management model:**  \n",
    "    2.1. Designing training stories  \n",
    "    2.2. Setting up the backend component  \n",
    "    2.3. Creating a custom action  \n",
    "    2.4. Defining the domain  \n",
    "    2.5. Training the dialogue model  \n",
    "    2.6. Testing the dialogue model   \n",
    "    2.7. Handling out-of-scope conversations  \n",
    "    2.8. Adding stories with multi-intents  \n",
    "    2.9. Evaluating dialogue model  \n",
    "      \n",
    "**3. Stage 3: Closing the feedback loop:**  \n",
    "    3.1. Improving the assistant using the interactive learning   \n",
    "    3.2. Storing conversation history    \n",
    "    3.3. Connecting the assistant to the outside world  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Intro\n",
    "In this section, we will install all the necessary dependencies needed to successfully run this exercise.\n",
    "### 0.1. Setup and installation\n",
    "The best way to insall the necessary modules is to use the requirements.txt file. After creating a virtual environment, run:\n",
    "\n",
    "**pip install -r requirements.txt**\n",
    "\n",
    "Throughout this workshop, we will use only open source tools. The code block below checks if Rasa NLU and Rasa Core have been installed suffessfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa_nlu.__version__, rasa_core.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Natural Language Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will enable your assistant to understand the user inputs by building a Rasa NLU model. This model will take unstructured user inputs and extract structured data in a form of intents and entities:  \n",
    "- *intent* - a label which represents the overall intention of the user 's input\n",
    "- *entity* - important detail which an assistant should extract and use to steer the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Designing a happy path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good starting point is to define a happy path first. A happy path is a conversation flow where the user provides all the required information and allows the assistant to lead the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Designing the NLU training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the NLU model you will need some labeled training data. Rasa NLU training data samples consist of the following components:  \n",
    "- intent label which starts with a prefix *\n",
    "- examples of text inputs which correspond to that label\n",
    "- entities which follow the format *[entity_value] (entity_label)*\n",
    "\n",
    "We will start by generating some training data examples by hand. For a completed data file check out the *helper_files/nlu_data.md* in the repository of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.3 Designing the training pipeline\n",
    "\n",
    "Once the training data is ready, we can define the NLU model. We can do that by constructing the processing pipeline which defines how structured data will be extracted from unstructured user inputs: how the sentences will be tokenized, what intent classifier will be used, what entity extraction model will be used, etc. Each component in a training pipeline is trained one after another and can take inputs from the previously defined component as well as pass some information to subsequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \n",
    "\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Training the first Rasa NLU Model\n",
    "Now, we're going to train the NLU model to recognise user inputs, so that when you send a message like \"hello\" to your bot, it will recognise this as a \"greet\" intent. Let's define the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "def train_nlu_model():\n",
    "    # loading the nlu training samples\n",
    "    training_data = load_data(\"nlu.md\")\n",
    "\n",
    "    # trainer to educate our pipeline\n",
    "    trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "    # train the model!\n",
    "    interpreter = trainer.train(training_data)\n",
    "\n",
    "    # store it for future use\n",
    "    model_directory = trainer.persist(\"./models/current\", fixed_model_name=\"nlu\")\n",
    "    \n",
    "    return interpreter, model_directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train the model using the previously defined data and model configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "We have trained the first version of our NLU model! Let's test it on various inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper function to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))\n",
    "\n",
    "#change the input message with your prefered inputs\n",
    "input_message = \"\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling out-of-scope inputs\n",
    "When dealing with conversational AI, out-of-scope user inputs are very common challenge. These inputs represent the user requests which have nothing to do with the assistant's job. While it's very challenging to provide a sensible answer to each out-of-scope input, it's important to enable your assistant to identify such inputs and guide the user back to the conversation. First, let's enable our assistant to identify out-of-scope inputs. To do that, we will add a new intent called *out-of-scope* to our training dataset and provde some corresponding inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the model and see how it deals with out-of-scope inputs now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Adding synonyms\n",
    "\n",
    "Synonyms are a very useful Rasa NLU feature which maps extracted entities to the same name. It's used when some extracted values have to be normalised so that they could be used to query the database or make an API call. In our example, the occupation of the relevant audience is a good candidate for the synonym because users can provide the same occupation in a variety of different ways (for example, Machine Learning and ML). Let's update our training examples with synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the NLU model with synonyms, we have to add the synonyms component to the model pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's retrain the NLU model and test the performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how 'machine learning engineers' now gets mapped to 'ML':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Implementing multi-intents\n",
    "\n",
    "The NLU model we have built so far works pretty well, but it only supports inputs with only one intent per user input. In this step, we will use a tensorflow embedding model to enable the assistant to recognise multi-intents - more than one intention per user input. Let's start by defining multi-intents in our training data. Multi-intents are defined in a very similar way as regular intents, the only difference is that the label names consists of intent tokens and a character of your choice that separates them, for example **intent_token1+intent_token2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's modify the configuration of the model pipeline to use the tensorflow_embedding model with multi-intent support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the model with the new pipeline and test the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how a two-question input now gets recognised as a multi-intent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Evaluating the NLU model\n",
    "\n",
    "\n",
    "Testing the model on various inputs is a good way to get high-level insights into the performance of the model. However, it's a time consuming and quite a tedious way of testing. Instead of evaluating the model by hand, it can also be evaluated on a test data set (though for simplicity we are going to use the same for test and train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rasa_nlu.evaluate import run_evaluation\n",
    "import IPython\n",
    "from IPython import display\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have just implemented the natural language understanding part of your assistant which means that your assistant can now understand you. In the second part of this workshop, we will delve into the next stage of the chatbot development - dialogue management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dialogue Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of this workshop you will build a machine learning-based dialogue model which will enable your assistant to decide on how to respond to user inputs based on the state of the conversation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Designing the training stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with generating the training data. Rasa Core models learn by observing real conversational data between the user and the assistant. The only important thing is that this data has to be converted into the Rasa Core format: user inputs have to be expressed as corresponding intents (and entities where necessary) while the responses of the assistant are expressed as action names. Each training story follows the format:  \n",
    "- the story starts with a story name which has a prefix ##  \n",
    "- intents, corresponding to user inputs, start with *  \n",
    "- if NLU model extracts entities which should influence the predictions of the dialogue model, they have to be included in the stories using the following format: * intent{'entity_name':\"entity_value\"}  \n",
    "- the responses of the bot start with -  \n",
    "- the story ends with an empty line which marks the end of the story\n",
    "\n",
    "In the next step of this tutorial, we will generate some training stories to cover the happy path. To see a complete training data example, check out the **data/stories.md** file of this repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Setting up the backend component\n",
    "\n",
    "We want to make our assistant engaging and fun. For that reason, we will enable it to answer the questions using the real data stored in a SQL database. For this exercise, the assistant will be able to pull information about the conference agenda, talks, and speakers. Let's take a look at how the data in a SQL database looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as lite\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Creating custom action\n",
    "\n",
    "We are going to use the backend integration to enable our assistant to fetch the relevant data based on user's queries. For that, we will create custom actions which, when predicted, will collect necessary data and use it to steer the conversation further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = \"\"\"\n",
    "from rasa_core_sdk import Action\n",
    "from rasa_core_sdk.events import SlotSet\n",
    "import sqlite3 as lite\n",
    "import random\n",
    "\n",
    "\n",
    "class ActionRecommendTalk(Action):\n",
    "    def name(self):\n",
    "        return \"\"\n",
    "        \n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        \n",
    "        \n",
    "        dispatcher.utter_message()\n",
    "\n",
    "\n",
    "        return []\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store actions > actions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Defining the domain\n",
    "\n",
    "Once we have the training data in place, we can define the domain of our assistant. A domain defines the environment in which the assistant operates - what user inputs it should expect to see, what actions it should be able to predict, what information the assistant should store throughout the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_yml = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Training the dialogue model\n",
    "\n",
    "We now have all the components necessary to train the dialogue management model. The code cell below will train the model using the defined policy and store the model in a specified location for us to test later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.policies import KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "def train_dialogue():\n",
    "    # loading our neatly defined training dialogues\n",
    "    agent = Agent(\"domain.yml\", policies=[MemoizationPolicy(), KerasPolicy()])\n",
    "    training_data = agent.load_data('stories.md')\n",
    "\n",
    "\n",
    "    agent.train(\n",
    "        training_data)\n",
    "\n",
    "    agent.persist('models/dialogue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Testing the dialogue model\n",
    "\n",
    "It's finally time for the most exciting part - testing the bot! Let's spin up the custom action server and we are ready to go. Open a new terminal and exacute the following command:\n",
    "\n",
    "**python -m rasa_core_sdk.endpoint --actions actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "import time\n",
    "\n",
    "def load_assistant():\n",
    "    messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "    interpreter = NaturalLanguageInterpreter.create(model_directory)\n",
    "    endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "    agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "\n",
    "    print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "    while True:\n",
    "        a = input()\n",
    "        if a == 'stop':\n",
    "            break\n",
    "        responses = agent.handle_text(a)\n",
    "        for response in responses:\n",
    "            print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Adding stories with multi-intents\n",
    "\n",
    "Next, let's add a few stories with multi-intents. Such stories will follow a regular data format, the only thing is that we can include a couple of actions to be predicted by an assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "               \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Adding out-of-scope inputs\n",
    "\n",
    "Finally, let's design a story with out-of-scope user inputs. Here, it's important to enable an assistant to take charge of the conversation and guide the user back to the initial conversation. In our case, an assistant will let the user know that it cannot deal with the out-of-scope request and will offer other questions to be asked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Dialogue model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great way to see how good our dialogue model is, is to test it using evaluation scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python -m rasa_core.evaluate --core models/dialogue --stories stories.md -o results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Closing the feedback loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing an assistant is just one part of the process. Another very important part which defines a successful assistant is enabling your assistant to learn from real user feedback. In the last part of this workshop, we will cover two ways to improve your bots using real user feedback - using interactive learning and using the history of the conversations. We will also, connect our assistant to a custom webpage to see how it works in action! We will complete this part using the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Improving the assistant using the interactive learning \n",
    "Interactive learning is a great way to improve your assistant and generate more training example by simply talking to your bot and providing feedback for all predictions it made. That is the main idea behind it - instead of responding right away, an assistant will tell you what it thinks it should do next and ask you for feedback. To start the interactive learning session, we will use a command line and use the following command:\n",
    "\n",
    "\n",
    "**python -m rasa_core.train interactive --core models/dialogue --nlu models/current/default/nlu --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Storing conversation history \n",
    "Another way to improve your assistant is to observe real conversations between the users and a bot. To do so, we have to store the conversations in a storage first. In Rasa Core, tracker is responsible of keeping track of everything that happends throughout the conversation - user inputs, NLU model results, dialogue model predictions, etc. We can easily store all this data in a database for later use. In this step you will learn how to store this information in a Mongo tracker store. We will complete this step in a command line.\n",
    "\n",
    "First, we will setup a mongodb backend and store the conversaton history there. For that, we will start our assistant on a server using:  \n",
    "**python -m rasa_core.run -d models/dialogue -u models/current/default/nlu --port 5005  --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.3. Connecting the assistant to the outside world\n",
    "In the very last step of this workshop, you will learn how to connect your assistant to a custom UI which can be easily added to a website of your choice. The repository of this workshop contains a folder called *bot_ui* where you can find a very basic html webpage. We will add a UI code stored in a *ui.html* file and connect our assistant to it. We will complete this step using a text editor and a command line.\n",
    "\n",
    "After setting up the backed, we will start our assistant on a server and connect to the UI using:\n",
    "\n",
    "**python -m rasa_core.run -d models/dialogue -u models/current/default/nlu --port 5005  --endpoints endpoints.yml --credentials credentials.yml**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Summary \n",
    "In this workshop, we covered some of the most important steps of the chatbot development and you should have a simple conference bot running your machine. There are so many things you can do to take this assistant to the whole new level! Here are some ideas for you:\n",
    "- Add new skills like:\n",
    "        show the session timetable \n",
    "        tell what is the next session at a specific venue   \n",
    "        connect with a speaker on social media  \n",
    "        recommend resources to learn more about the topic  \n",
    "        \n",
    "- Add new entities like date and time\n",
    "- Connect your assistant to the most popular messaging platforms like Facebook, Slack or Telegram\n",
    "\n",
    "Make sure to reference [Rasa official documentation](https://rasa.com/docs) or ask questions on the [Rasa Community Forum](https://forum.rasa.com) if you are in doubt! \n",
    "\n",
    "Most importantly, let me know what you came up with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
